import torch
from typing import List, Optional, Tuple, Dict, Set
from .pq_utils import sa_encode_4d_keops, sa_decode_4d, DynamicPQCache
from .Singleton import Singleton
from .Timer import Timer
import logging

logger = logging.getLogger(__name__)

class PageManager:
    """
    é¡µé¢å†…å­˜ç®¡ç†å™¨
    è´Ÿè´£ç®¡ç†VçŸ©é˜µè½¬ç½®å­˜å‚¨çš„é¡µé¢åˆ†é…å’Œé‡Šæ”¾
    æ”¯æŒåŠ¨æ€é¡µé¢æ‰©å±•
    """
    
    def __init__(self, page_size: int = 64, initial_pages: int = 100, max_pages: int = None, M: int = 64, device='cuda'):
        """
        åˆå§‹åŒ–é¡µé¢ç®¡ç†å™¨
        
        Args:
            page_size: æ¯ä¸ªé¡µé¢åŒ…å«çš„tokenæ•°é‡ï¼Œé»˜è®¤64
            initial_pages: åˆå§‹é¡µé¢æ•°é‡ï¼Œé»˜è®¤100
            max_pages: æœ€å¤§é¡µé¢æ•°é‡ï¼ŒNoneè¡¨ç¤ºæ— é™åˆ¶ï¼ˆä»…å—å†…å­˜é™åˆ¶ï¼‰
            M: PQçš„å­ç©ºé—´æ•°é‡
            device: è®¾å¤‡ç±»å‹
        """
        self.page_size = page_size  # 64 tokens per page
        self.M = M  # å­ç©ºé—´æ•°é‡
        self.device = device
        self.initial_pages = initial_pages
        self.max_pages = max_pages  # None è¡¨ç¤ºæ— é™åˆ¶
        
        # ä¿®å¤ï¼šæ›´åˆç†çš„é¢„åˆ†é…ç­–ç•¥
        # é¢„åˆ†é…å¤§å°åº”è¯¥ç‹¬ç«‹äºmax_pagesï¼Œé¿å…é€»è¾‘æ··ä¹±
        if max_pages is not None:
            # ç¡®ä¿é¢„åˆ†é…ä¸è¶…è¿‡max_pages
            self.preallocated_size = min(initial_pages * 2, max_pages)
        else:
            self.preallocated_size = min(initial_pages * 2, 1024)  # é»˜è®¤é¢„åˆ†é…å¤§å°
        
        self.current_active_pages = initial_pages  # å½“å‰æ¿€æ´»çš„é¡µé¢æ•°
        
        # é¢„åˆ†é…å¤§é¡µé¢æ± ï¼š(preallocated_size, M, page_size) for transposed storage
        # åªæœ‰å‰ initial_pages ä¸ªé¡µé¢æ˜¯æ¿€æ´»çš„
        self.page_pool = torch.zeros(
            (self.preallocated_size, M, page_size), dtype=torch.uint8, device=device
        )
        
        # é¡µé¢ç®¡ç†çŠ¶æ€
        self.free_pages: Set[int] = set(range(initial_pages))
        self.allocated_pages: Dict[int, Dict] = {}  # page_id -> usage_info
        
        # åŠ¨æ€æ‰©å±•ç»Ÿè®¡
        self.expansion_count = 0
        self.total_expansions = 0
        
        # æ”¹è¿›ï¼šæ·»åŠ é¡µé¢å¤ç”¨ç»Ÿè®¡
        self.page_reuse_count = 0
        self.total_allocations = 0
        
        logger.info(f"PageManager initialized: {initial_pages} active pages (pre-allocated {self.preallocated_size}), "
                   f"max: {'unlimited' if max_pages is None else max_pages}, {page_size} tokens/page, {M} subspaces")
    
    def _expand_page_pool(self, additional_pages: int = None, force_expansion: bool = False):
        """
        åŠ¨æ€æ‰©å±•é¡µé¢æ± 
        
        Args:
            additional_pages: è¦æ·»åŠ çš„é¡µé¢æ•°ï¼Œé»˜è®¤ä¸ºå½“å‰æ± å¤§å°çš„50%
            force_expansion: æ˜¯å¦å¼ºåˆ¶æ‰©å±•ï¼Œç”¨äºé¢„å¡«å……é˜¶æ®µä¸€æ¬¡æ€§æ‰©å±•è¶³å¤Ÿé¡µé¢
        """
        if additional_pages is None:
            if force_expansion:
                # é¢„å¡«å……é˜¶æ®µï¼šä¸€æ¬¡æ€§æ‰©å±•è¶³å¤Ÿé¡µé¢ï¼Œé¿å…é¢‘ç¹æ‰©å±•
                additional_pages = max(self.current_active_pages, 100)  # è‡³å°‘æ‰©å±•100é¡µ
                logger.info(f"Force expansion for prefill: adding {additional_pages} pages")
            else:
                # æ­£å¸¸æ‰©å±•ï¼šå½“å‰æ¿€æ´»é¡µé¢æ•°çš„50%
                additional_pages = max(self.current_active_pages // 2, 50)  # è‡³å°‘æ‰©å±•50é¡µ
        
        # ä¿®å¤ï¼šä¼˜åŒ–é¡µé¢æ‰©å±•é™åˆ¶æ£€æŸ¥
        if self.max_pages is not None:
            max_additional = self.max_pages - self.current_active_pages
            if max_additional <= 0:
                # å¦‚æœå·²è¾¾åˆ°æœ€å¤§é¡µé¢é™åˆ¶ï¼Œå°è¯•æ¸…ç†ä¸€äº›é¡µé¢æˆ–ç»™å‡ºæ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                logger.warning(f"Page pool at max capacity: {self.current_active_pages}/{self.max_pages}")
                logger.warning(f"Allocated pages: {len(self.allocated_pages)}, Free pages: {len(self.free_pages)}")
                raise RuntimeError(f"Cannot expand page pool: reached max_pages limit {self.max_pages}")
            
            # ç¡®ä¿æ‰©å±•çš„é¡µé¢æ•°ä¸è¶…è¿‡é™åˆ¶
            if additional_pages > max_additional:
                logger.warning(f"Requested expansion ({additional_pages}) exceeds available capacity ({max_additional})")
                additional_pages = max_additional
        
        # æ£€æŸ¥é¢„åˆ†é…çš„é¡µé¢æ± æ˜¯å¦æœ‰è¶³å¤Ÿç©ºé—´
        new_active_size = self.current_active_pages + additional_pages
        
        if new_active_size <= self.preallocated_size:
            # æ— éœ€é‡æ–°åˆ†é…å†…å­˜ï¼Œç›´æ¥æ¿€æ´»é¢„åˆ†é…çš„é¡µé¢
            logger.info(f"Activating {additional_pages} pre-allocated pages ({self.current_active_pages} â†’ {new_active_size})")
            
            # æ·»åŠ æ–°çš„ç©ºé—²é¡µé¢ï¼ˆæ¥è‡ªé¢„åˆ†é…æ± ï¼‰
            for i in range(self.current_active_pages, new_active_size):
                self.free_pages.add(i)
                # æ¸…é›¶é¢„åˆ†é…çš„é¡µé¢
                self.page_pool[i].fill_(0)
            
        else:
            # éœ€è¦çœŸæ­£æ‰©å±•å†…å­˜ï¼ˆé¢„åˆ†é…ç©ºé—´ä¸è¶³ï¼‰
            actual_new_size = max(new_active_size, self.preallocated_size * 2)
            logger.warning(f"Pre-allocated space insufficient, expanding memory from {self.preallocated_size} to {actual_new_size}")
            
            # åˆ›å»ºæ–°çš„æ›´å¤§é¡µé¢æ± 
            new_pool = torch.zeros(
                (actual_new_size, self.M, self.page_size), dtype=torch.uint8, device=self.device
            )
            
            # å¤åˆ¶ç°æœ‰æ•°æ®
            new_pool[:self.current_active_pages] = self.page_pool[:self.current_active_pages]
            
            # æ›¿æ¢é¡µé¢æ± 
            self.page_pool = new_pool
            self.preallocated_size = actual_new_size
            
            # æ·»åŠ æ–°çš„ç©ºé—²é¡µé¢
            for i in range(self.current_active_pages, new_active_size):
                self.free_pages.add(i)
        
        # æ›´æ–°çŠ¶æ€
        self.current_active_pages = new_active_size
        self.total_expansions += 1
        
        logger.info(f"Page pool expanded successfully: {len(self.free_pages)} free pages available, "
                   f"active: {self.current_active_pages}/{self.preallocated_size}")
    
    def allocate_page(self) -> int:
        """
        åˆ†é…ä¸€ä¸ªæ–°é¡µé¢ï¼Œè¿”å›é¡µé¢ID
        æ”¯æŒåŠ¨æ€æ‰©å±•
        
        Returns:
            page_id: åˆ†é…çš„é¡µé¢ID
            
        Raises:
            RuntimeError: å½“è¾¾åˆ°æœ€å¤§é¡µé¢é™åˆ¶ä¸”æ— æ³•æ‰©å±•æ—¶
        """
        # å¦‚æœæ²¡æœ‰ç©ºé—²é¡µé¢ï¼Œå°è¯•æ‰©å±•é¡µé¢æ± 
        if not self.free_pages:
            try:
                self._expand_page_pool()
            except RuntimeError as e:
                raise RuntimeError(f"No free pages available and cannot expand: {e}")
        
        page_id = self.free_pages.pop()
        self.allocated_pages[page_id] = {
            'allocated_at': torch.cuda.current_stream().query() if torch.cuda.is_available() else 0,
            'allocation_count': 1,  # è®°å½•åˆ†é…æ¬¡æ•°
            'last_used': torch.cuda.current_stream().query() if torch.cuda.is_available() else 0
        }
        
        # å»æ‰åˆ†é…æ—¶çš„æ¸…é›¶ï¼Œé¿å…é‡å¤memsetï¼ŒæŒ‰éœ€åœ¨å†™å…¥é˜¶æ®µå¤„ç†å°¾éƒ¨æ¸…é›¶
        self.total_allocations += 1
        logger.debug(f"Allocated page {page_id}, remaining free pages: {len(self.free_pages)}")
        return page_id
    
    def allocate_reused_page(self) -> int:
        """
        åˆ†é…ä¸€ä¸ªå¤ç”¨é¡µé¢ï¼Œä¼˜å…ˆé€‰æ‹©æœ€è¿‘ä½¿ç”¨çš„é¡µé¢
        æ”¯æŒåŠ¨æ€æ‰©å±•
        
        Returns:
            page_id: åˆ†é…çš„é¡µé¢ID
            
        Raises:
            RuntimeError: å½“è¾¾åˆ°æœ€å¤§é¡µé¢é™åˆ¶ä¸”æ— æ³•æ‰©å±•æ—¶
        """
        # å¦‚æœæ²¡æœ‰ç©ºé—²é¡µé¢ï¼Œå°è¯•æ‰©å±•é¡µé¢æ± 
        if not self.free_pages:
            try:
                self._expand_page_pool()
            except RuntimeError as e:
                raise RuntimeError(f"No free pages available and cannot expand: {e}")
        
        # ä¼˜å…ˆé€‰æ‹©æœ€è¿‘ä½¿ç”¨çš„é¡µé¢è¿›è¡Œå¤ç”¨
        page_id = self.free_pages.pop()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¤ç”¨é¡µé¢
        if page_id in self.allocated_pages:
            self.page_reuse_count += 1
            self.allocated_pages[page_id]['allocation_count'] += 1
            self.allocated_pages[page_id]['last_used'] = torch.cuda.current_stream().query() if torch.cuda.is_available() else 0
            logger.debug(f"Reused page {page_id} (reuse count: {self.allocated_pages[page_id]['allocation_count']})")
        else:
            self.allocated_pages[page_id] = {
                'allocated_at': torch.cuda.current_stream().query() if torch.cuda.is_available() else 0,
                'allocation_count': 1,
                'last_used': torch.cuda.current_stream().query() if torch.cuda.is_available() else 0
            }
        
        # å»æ‰åˆ†é…æ—¶çš„æ¸…é›¶ï¼Œé¿å…é‡å¤memset
        self.total_allocations += 1
        logger.debug(f"Allocated page {page_id}, remaining free pages: {len(self.free_pages)}")
        return page_id
    
    def allocate_pages(self, n: int) -> list:
        """æ‰¹é‡åˆ†é…nä¸ªé¡µé¢ï¼Œå¿…è¦æ—¶è‡ªåŠ¨æ‰©å®¹ã€‚"""
        if n <= 0:
            return []
        if len(self.free_pages) < n:
            try:
                self._expand_page_pool(additional_pages=n - len(self.free_pages), force_expansion=True)
            except RuntimeError as e:
                raise RuntimeError(f"Cannot bulk-allocate pages: {e}")
        ids = []
        for _ in range(n):
            pid = self.free_pages.pop()
            self.allocated_pages[pid] = {
                'allocated_at': torch.cuda.current_stream().query() if torch.cuda.is_available() else 0,
                'allocation_count': self.allocated_pages.get(pid, {}).get('allocation_count', 0) + 1,
                'last_used': torch.cuda.current_stream().query() if torch.cuda.is_available() else 0
            }
            ids.append(pid)
            self.total_allocations += 1
        return ids
    
    def free_page(self, page_id: int):
        """
        é‡Šæ”¾é¡µé¢
        
        Args:
            page_id: è¦é‡Šæ”¾çš„é¡µé¢ID
        """
        if page_id not in self.allocated_pages:
            logger.warning(f"Attempting to free unallocated page {page_id}")
            return
        
        del self.allocated_pages[page_id]
        self.free_pages.add(page_id)
        
        logger.debug(f"Freed page {page_id}, available free pages: {len(self.free_pages)}")
    
    def get_page(self, page_id: int) -> torch.Tensor:
        """
        è·å–é¡µé¢æ•°æ®ï¼Œè¿”å›è½¬ç½®å­˜å‚¨çš„é¡µé¢
        
        Args:
            page_id: é¡µé¢ID
            
        Returns:
            page_data: å½¢çŠ¶ä¸º (M, page_size) çš„è½¬ç½®å­˜å‚¨é¡µé¢
        """
        # é¡µé¢IDæœ‰æ•ˆæ€§æ£€æŸ¥
        if not self._is_valid_page_id(page_id):
            raise ValueError(f"Invalid page_id {page_id}: must be within [0, {self.current_active_pages})")
        
        if page_id not in self.allocated_pages:
            raise ValueError(f"Page {page_id} is not allocated")
        
        # æ›´æ–°æœ€åä½¿ç”¨æ—¶é—´
        self.allocated_pages[page_id]['last_used'] = torch.cuda.current_stream().query() if torch.cuda.is_available() else 0
        
        return self.page_pool[page_id]
    
    def _is_valid_page_id(self, page_id: int) -> bool:
        """
        æ£€æŸ¥é¡µé¢IDæ˜¯å¦æœ‰æ•ˆ
        
        Args:
            page_id: è¦æ£€æŸ¥çš„é¡µé¢ID
            
        Returns:
            bool: é¡µé¢IDæ˜¯å¦æœ‰æ•ˆ
        """
        return (
            isinstance(page_id, int) and 
            0 <= page_id < self.current_active_pages and
            page_id < self.preallocated_size
        )
    
    def safe_page_access(self, page_id: int) -> torch.Tensor:
        """
        å®‰å…¨çš„é¡µé¢è®¿é—®ï¼ŒåŒ…å«å®Œæ•´çš„è¾¹ç•Œæ£€æŸ¥
        
        Args:
            page_id: é¡µé¢ID
            
        Returns:
            é¡µé¢å¼ é‡
            
        Raises:
            ValueError: é¡µé¢IDæ— æ•ˆ
        """
        if not self._is_valid_page_id(page_id):
            error_msg = (f"Invalid page access: page_id={page_id}, "
                        f"valid range=[0, {self.current_active_pages}), "
                        f"preallocated_size={self.preallocated_size}")
            logger.error(error_msg)
            raise ValueError(error_msg)
        
        return self.page_pool[page_id]
    
    def get_stats(self) -> Dict:
        """è·å–é¡µé¢ç®¡ç†å™¨ç»Ÿè®¡ä¿¡æ¯"""
        reuse_rate = (self.page_reuse_count / self.total_allocations * 100) if self.total_allocations > 0 else 0
        return {
            'initial_pages': self.initial_pages,
            'current_active_pages': self.current_active_pages,
            'preallocated_size': self.preallocated_size,
            'max_pages': self.max_pages,
            'allocated_pages': len(self.allocated_pages),
            'free_pages': len(self.free_pages),
            'utilization': len(self.allocated_pages) / self.current_active_pages if self.current_active_pages > 0 else 0,
            'memory_usage_mb': (self.page_pool.numel() * self.page_pool.element_size()) / (1024 * 1024),
            'memory_efficiency': (self.current_active_pages / self.preallocated_size * 100) if self.preallocated_size > 0 else 0,
            'page_reuse_count': self.page_reuse_count,
            'total_allocations': self.total_allocations,
            'reuse_rate_percent': reuse_rate,
            'total_expansions': self.total_expansions,
            'expansion_efficiency': (self.current_active_pages - self.initial_pages) / self.initial_pages * 100 if self.initial_pages > 0 else 0
        }


def quantize_and_transpose_batch(v_batch: torch.Tensor, centroids: torch.Tensor) -> torch.Tensor:
    """
    é‡åŒ–å¹¶è½¬ç½®ä¸€ä¸ªbatchçš„Væ•°æ®
    
    Args:
        v_batch: (64, d) - 64ä¸ªtokençš„Vå‘é‡
        centroids: (M, C, d/M) - Vçš„ç æœ¬
    
    Returns:
        transposed_codes: (M, 64) - è½¬ç½®åçš„é‡åŒ–ç 
    """
    # ç¡®ä¿è¾“å…¥æ˜¯è¿ç»­çš„
    v_batch = v_batch.contiguous()
    
    # é‡åŒ–ï¼š(64, d) -> (1, 1, 64, M) -> (64, M)
    v_codes = sa_encode_4d_keops(
        v_batch.unsqueeze(0).unsqueeze(0),  # æ·»åŠ batchå’Œheadç»´åº¦: (1, 1, 64, d)
        centroids, target_dtype=torch.uint8
    ).squeeze(0).squeeze(0)  # ç§»é™¤batchå’Œheadç»´åº¦: (64, M)
    
    # è½¬ç½®ï¼š(64, M) -> (M, 64)
    transposed_codes = v_codes.transpose(0, 1).contiguous()
    
    return transposed_codes


class PagedPQCache(DynamicPQCache):
    """
    æ‰©å±•çš„é¡µå¼PQç¼“å­˜ï¼Œå…¼å®¹åŸæœ‰DynamicPQCacheæ¥å£
    
    ä¸»è¦æ”¹è¿›ï¼š
    1. æ‰©å±•æ®‹å·®ç¼“å­˜ä»64åˆ°128 tokens
    2. VçŸ©é˜µé‡‡ç”¨è½¬ç½®å­˜å‚¨çš„é¡µå¼ç®¡ç†
    3. ä¼˜åŒ–è®¿å­˜æ¨¡å¼ï¼Œæé«˜cacheåˆ©ç”¨ç‡
    """
    
    def __init__(self, *, bs, nh, num_key_value_heads, M, layer_num, 
                 dtype=torch.uint8, nbits=8, d=128, scalar_t=torch.float32,
                 page_size=64, extended_residual_size=128, max_pages_per_layer=None):
        """
        åˆå§‹åŒ–é¡µå¼PQç¼“å­˜
        
        Args:
            page_size: é¡µé¢å¤§å°ï¼ˆtokensï¼‰ï¼Œé»˜è®¤64
            extended_residual_size: æ‰©å±•æ®‹å·®ç¼“å­˜å¤§å°ï¼Œé»˜è®¤128
            max_pages_per_layer: æ¯å±‚æœ€å¤§é¡µé¢æ•°ï¼ŒNoneè¡¨ç¤ºæ— é™åˆ¶ï¼ˆè‡ªåŠ¨è®¡ç®—ï¼‰
        """
        # é¡µå¼å­˜å‚¨ç‰¹æœ‰å‚æ•°
        self.page_size = page_size  # 64 tokens per page
        self.extended_residual_size = extended_residual_size  # 128 tokens
        self.max_pages_per_layer = max_pages_per_layer

        # æ‰‹åŠ¨è®¾ç½®çˆ¶ç±»çš„å±æ€§ï¼Œé¿å…è°ƒç”¨init_cache
        self.bs = bs
        self.nh = nh
        self.num_key_value_heads = num_key_value_heads
        self.M = M
        self.layer_num = layer_num
        self.dtype = dtype
        self.nbits = nbits
        self.d = d
        self.scalar_t = scalar_t
        
        # è®¾ç½®çˆ¶ç±»çš„å…¶ä»–å±æ€§
        self.max_residual_length = extended_residual_size  # ç›´æ¥è®¾ç½®ä¸ºæ‰©å±•å¤§å°
        
        # å¯¼å…¥KernelRegistry
        from .pq_utils import KernelRegistry
        self.registery = KernelRegistry(M=M, d=d, nbits=nbits, nh=nh, scalar_t=scalar_t)
        
        # åˆå§‹åŒ–é¡µé¢ç®¡ç†å™¨
        # ä¿®å¤ï¼šæ›´åˆç†çš„åˆå§‹é¡µé¢è®¡ç®—ç­–ç•¥
        
        # åŸºç¡€éœ€æ±‚ï¼šæ¯ä¸ªbatch-headç»„åˆçš„æœ€å°é¡µé¢éœ€æ±‚
        base_pages_needed = self.bs * self.num_key_value_heads * 2  # Kå’ŒVå„éœ€è¦è‡³å°‘1ä¸ªé¡µé¢
        
        # é’ˆå¯¹1024 token prefillçš„éœ€æ±‚è®¡ç®—
        prefill_1024_tokens = 1024
        pages_per_1024 = (prefill_1024_tokens + self.page_size - 1) // self.page_size  # 16é¡µ
        pages_for_1024_prefill = self.bs * self.num_key_value_heads * pages_per_1024  # 1*32*16 = 512é¡µ
        
        # ä¿®å¤ï¼šå‡å°initial_pagesï¼Œé¿å…æ¥è¿‘max_pagesé™åˆ¶
        # åˆå§‹é¡µé¢æ•°åº”è¯¥è¾ƒå°ï¼Œè®©é¡µé¢ç®¡ç†å™¨æŒ‰éœ€æ‰©å±•
        initial_pages = max(
            base_pages_needed,  # æœ€å°éœ€æ±‚
            100                  # åˆç†çš„åˆå§‹å€¼ï¼Œé¿å…è¿‡åº¦é¢„åˆ†é…
        )
        
        logger.info(f"Smart initial page calculation: "
                   f"bs={self.bs}, kv_heads={self.num_key_value_heads}, page_size={self.page_size}")
        logger.info(f"  - Base need: {base_pages_needed} pages")
        logger.info(f"  - 1024 token prefill need: {pages_for_1024_prefill} pages")  
        logger.info(f"  - Selected initial: {initial_pages} pages (conservative to allow expansion)")
        
        # æœ€å¤§é¡µé¢æ•°ï¼šå¦‚æœç”¨æˆ·æŒ‡å®šäº†max_pages_per_layerï¼Œåˆ™ä½¿ç”¨ï¼›å¦åˆ™è®¾ç½®åˆç†é»˜è®¤å€¼
        if self.max_pages_per_layer is None:
            # ä¿®å¤ï¼šä¸º1024 token prefillè®¾ç½®åˆç†çš„max_pages
            # éœ€è¦ç¡®ä¿èƒ½å®¹çº³å®Œæ•´çš„prefill + ä¸€äº›ä½™é‡
            max_pages = pages_for_1024_prefill * 2  # 1024é¡µï¼Œè¶³å¤Ÿ1024 token prefill + ä½™é‡
            logger.info(f"Auto-calculated max_pages: {max_pages} (2x of 1024-token prefill needs)")
        else:
            max_pages = self.max_pages_per_layer
            # éªŒè¯max_pagesæ˜¯å¦è¶³å¤Ÿ
            if max_pages < pages_for_1024_prefill:
                logger.warning(f"Specified max_pages ({max_pages}) may be insufficient for 1024-token prefill ({pages_for_1024_prefill})")
                max_pages = pages_for_1024_prefill * 2
                logger.warning(f"Increasing max_pages to {max_pages}")
        
        # åˆ›å»ºé¡µé¢ç®¡ç†å™¨
        self.page_managers = [
            PageManager(
                page_size=page_size, 
                initial_pages=initial_pages,  # ä½¿ç”¨è¾ƒå°çš„åˆå§‹å€¼
                max_pages=max_pages,          # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ‰©å±•ç©ºé—´
                M=M, 
                device='cuda'
            )
            for _ in range(layer_num)
        ]
        
        # Ké¡µé¢IDåˆ—è¡¨ï¼šæ¯å±‚ç»´æŠ¤é¡µé¢IDåˆ—è¡¨ï¼Œæ”¯æŒå¤šbatchå’Œå¤šhead
        # ç»“æ„ï¼š[layer][batch][head] -> List[page_id]
        self.key_page_ids = [
            [[[] for _ in range(num_key_value_heads)] for _ in range(bs)]
            for _ in range(layer_num)
        ]
        
        # Vé¡µé¢IDåˆ—è¡¨ï¼šæ¯å±‚ç»´æŠ¤é¡µé¢IDåˆ—è¡¨ï¼Œæ”¯æŒå¤šbatchå’Œå¤šhead
        # ç»“æ„ï¼š[layer][batch][head] -> List[page_id]
        self.value_page_ids = [
            [[[] for _ in range(num_key_value_heads)] for _ in range(bs)]
            for _ in range(layer_num)
        ]
        
        # é‡æ–°åˆå§‹åŒ–ç¼“å­˜ï¼ˆè¦†ç›–çˆ¶ç±»çš„åˆå§‹åŒ–ï¼‰
        self._init_paged_cache()
        
        # æ£€æŸ¥é¡µå¼å†…æ ¸å¯ç”¨æ€§
        # self._check_paged_kernel_availability()
        
        logger.info(f"PagedPQCache initialized: {layer_num} layers, {extended_residual_size} residual tokens, "
                   f"{page_size} tokens/page, initial={initial_pages}, max={max_pages}")
        
        # æ”¹è¿›ï¼šæ˜¾ç¤ºè¯¦ç»†çš„é…ç½®ä¿¡æ¯å’Œé¢„æœŸæ€§èƒ½
        logger.info(f"ğŸ“‹ é…ç½®è¯¦æƒ…:")
        logger.info(f"   - æ¨¡å‹é…ç½®: {self.bs} batch Ã— {self.num_key_value_heads} heads Ã— {self.M} subspaces")
        logger.info(f"   - å­˜å‚¨ç­–ç•¥: KçŸ©é˜µ(ä¼ ç»Ÿ) + VçŸ©é˜µ(é¡µé¢è½¬ç½®)")
        logger.info(f"   - é¡µé¢ç®¡ç†: {initial_pages} initial pages/layer, max={max_pages} pages/layer Ã— {layer_num} layers")
        logger.info(f"   - å†…å­˜ä¼˜åŒ–: é¢„å¡«å……æ®‹å·®({self.page_size} tokens) + è§£ç æ®‹å·®({self.extended_residual_size} tokens)")
        logger.info(f"   - åŠ¨æ€æ‰©å±•: æ”¯æŒè‡ªåŠ¨é¡µé¢æ± æ‰©å±•ï¼ŒæŒ‰éœ€åˆ†é…å†…å­˜")
        
        # è®¡ç®—åˆå§‹å†…å­˜ä½¿ç”¨
        initial_page_memory = (initial_pages * self.M * self.page_size * 2) / (1024 * 1024)  # MB
        initial_total_memory = initial_page_memory * layer_num
        max_page_memory = (max_pages * self.M * self.page_size * 2) / (1024 * 1024)  # MB
        max_total_memory = max_page_memory * layer_num
        
        logger.info(f"ğŸ’¾ å†…å­˜ä½¿ç”¨é¢„ä¼°:")
        logger.info(f"   - åˆå§‹å†…å­˜: {initial_total_memory:.2f} MB ({initial_page_memory:.2f} MB/layer)")
        logger.info(f"   - æœ€å¤§å†…å­˜: {max_total_memory:.2f} MB ({max_page_memory:.2f} MB/layer)")
        logger.info(f"   - æ‰©å±•ç­–ç•¥: æŒ‰éœ€æ‰©å±•ï¼Œé¿å…å†…å­˜æµªè´¹")
    
    def _init_paged_cache(self):
        """åˆå§‹åŒ–é¡µå¼ç¼“å­˜ç»“æ„"""
        # KçŸ©é˜µï¼šä½¿ç”¨ä¼ ç»Ÿå­˜å‚¨ï¼ˆrow-wiseï¼‰ï¼Œä¼˜åŒ–attentionè®¡ç®—
        self.key_cache = [
            torch.zeros((self.bs, self.num_key_value_heads, 0, self.M), dtype=self.dtype, device='cuda')
            for _ in range(self.layer_num)
        ]
        
        # VçŸ©é˜µï¼šä½¿ç”¨é¡µé¢å­˜å‚¨ï¼Œè¿™é‡Œä¸éœ€è¦ç›´æ¥çš„value_cache
        # ä½†ä¿ç•™ä½œä¸ºfallbacké€‰é¡¹
        self.value_cache = [
            torch.zeros((self.bs, self.num_key_value_heads, 0, self.M), dtype=self.dtype, device='cuda')
            for _ in range(self.layer_num)
        ]
        
        # æ”¹è¿›ï¼šä¼˜åŒ–æ®‹å·®ç¼“å­˜å¤§å°ï¼Œæ ¹æ®å®é™…ä½¿ç”¨åœºæ™¯åŠ¨æ€è°ƒæ•´
        # é¢„å¡«å……é˜¶æ®µï¼šä½¿ç”¨è¾ƒå°çš„æ®‹å·®ç¼“å­˜ï¼ˆ64 tokensï¼‰
        # è§£ç é˜¶æ®µï¼šä½¿ç”¨è¾ƒå¤§çš„æ®‹å·®ç¼“å­˜ï¼ˆ128 tokensï¼‰
        prefill_residual_size = self.page_size  # 64 tokens
        decoding_residual_size = self.extended_residual_size  # 128 tokens
        
        # é¢„å¡«å……æ®‹å·®ç¼“å­˜ï¼ˆè¾ƒå°ï¼ŒèŠ‚çœå†…å­˜ï¼‰
        self.key_prefill_residual = [
            torch.zeros((self.bs, self.num_key_value_heads, prefill_residual_size, self.d), 
                       dtype=self.scalar_t, device='cuda')
            for _ in range(self.layer_num)
        ]
        
        self.value_prefill_residual = [
            torch.zeros((self.bs, self.num_key_value_heads, prefill_residual_size, self.d), 
                       dtype=self.scalar_t, device='cuda')
            for _ in range(self.layer_num)
        ]
        
        # è§£ç æ®‹å·®ç¼“å­˜ï¼ˆè¾ƒå¤§ï¼Œæ”¯æŒé•¿åºåˆ—ï¼‰
        self.key_residual_cache = [
            torch.zeros((self.bs, self.num_key_value_heads, decoding_residual_size, self.d), 
                       dtype=self.scalar_t, device='cuda')
            for _ in range(self.layer_num)
        ]
        
        self.value_residual_cache = [
            torch.zeros((self.bs, self.num_key_value_heads, decoding_residual_size, self.d), 
                       dtype=self.scalar_t, device='cuda')
            for _ in range(self.layer_num)
        ]
        
        # é‡ç½®è®¡æ•°å™¨
        self.seen_tokens = [0 for _ in range(self.layer_num)]
        self.residualed_tokens = [0 for _ in range(self.layer_num)]
        
        # æ”¹è¿›ï¼šæ·»åŠ å†…å­˜ä½¿ç”¨ç»Ÿè®¡
        total_memory_mb = (
            sum(cache.numel() * cache.element_size() for cache in self.key_cache + self.value_cache) +
            sum(cache.numel() * cache.element_size() for cache in self.key_prefill_residual + self.value_prefill_residual) +
            sum(cache.numel() * cache.element_size() for cache in self.key_residual_cache + self.value_residual_cache)
        ) / (1024 * 1024)
        
        logger.info(f"PagedPQCache memory initialized: {total_memory_mb:.2f} MB "
                   f"(K_traditional: {len(self.key_cache)} layers, "
                   f"V_pages: {len(self.value_cache)} layers, "
                   f"residual: {prefill_residual_size + decoding_residual_size} tokens)")
    
    def flush_to_pages(self, layer_idx: int):
        """
        å°†æ®‹å·®ç¼“å­˜çš„å‰64ä¸ªtoken flushåˆ°é¡µé¢å­˜å‚¨
        
        æ”¹è¿›ï¼šKçŸ©é˜µä½¿ç”¨ä¼ ç»Ÿå­˜å‚¨ï¼ŒVçŸ©é˜µä½¿ç”¨é¡µé¢å­˜å‚¨
        
        Args:
            layer_idx: å±‚ç´¢å¼•
        """
        logger.info(f"flush_to_pagesè¢«è°ƒç”¨: layer_idx={layer_idx}, residualed_tokens={self.residualed_tokens[layer_idx]}, page_size={self.page_size}")
        
        if self.residualed_tokens[layer_idx] < self.page_size:
            logger.debug(f"Layer {layer_idx}: Not enough tokens to flush ({self.residualed_tokens[layer_idx]}/{self.page_size})")
            return  # ä¸è¶³64ä¸ªtokenï¼Œæ— éœ€flush
        
        logger.debug(f"Layer {layer_idx}: Flushing {self.page_size} tokens to pages")
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        logger.debug(f"flush_to_pageså¼€å§‹æ—¶çš„ç¼“å­˜å½¢çŠ¶:")
        logger.debug(f"  key_residual_cache[{layer_idx}]: {self.key_residual_cache[layer_idx].shape}")
        logger.debug(f"  value_residual_cache[{layer_idx}]: {self.value_residual_cache[layer_idx].shape}")
        
        # æå–å‰64ä¸ªtokençš„KV
        k_to_flush = self.key_residual_cache[layer_idx][:, :, :self.page_size, :]  # (bs, nh_k, 64, d)
        v_to_flush = self.value_residual_cache[layer_idx][:, :, :self.page_size, :]  # (bs, nh_k, 64, d)
        
        logger.debug(f"æå–çš„KVå½¢çŠ¶:")
        logger.debug(f"  k_to_flush: {k_to_flush.shape}")
        logger.debug(f"  v_to_flush: {v_to_flush.shape}")
        
        # æ”¹è¿›ï¼šKçŸ©é˜µä½¿ç”¨ä¼ ç»Ÿå­˜å‚¨ï¼ˆrow-wiseï¼‰ï¼Œä¼˜åŒ–attentionè®¡ç®—
        k_codes = sa_encode_4d_keops(k_to_flush, self.key_cent, target_dtype=self.dtype)  # (bs, nh_k, 64, M)
        self.key_cache[layer_idx] = torch.cat([self.key_cache[layer_idx], k_codes], dim=2)
        
        logger.debug(f"KçŸ©é˜µä½¿ç”¨ä¼ ç»Ÿå­˜å‚¨ï¼Œæ›´æ–°åçš„å½¢çŠ¶: {self.key_cache[layer_idx].shape}")
        
        # VçŸ©é˜µï¼šä½¿ç”¨é¡µé¢å­˜å‚¨ï¼ˆè½¬ç½®æ ¼å¼ï¼‰ï¼Œä¼˜åŒ–å†…å­˜è®¿é—®
        v_codes = sa_encode_4d_keops(v_to_flush, self.value_cent, target_dtype=self.dtype)  # (bs, nh_k, 64, M)
        
        logger.debug(f"Vç¼–ç åçš„å½¢çŠ¶: {v_codes.shape}")
        
        # ä¸ºæ¯ä¸ªbatchå’Œheadåˆ†é…Vé¡µé¢å¹¶è½¬ç½®å­˜å‚¨
        # è®°å½•åˆ†é…å¤±è´¥çš„batch-headç»„åˆï¼Œç”¨äºfallback
        failed_v_allocations = []
        successful_v_allocations = 0
        
        for b in range(self.bs):
            for h in range(self.num_key_value_heads):
                # åˆ†é…Vé¡µé¢
                try:
                    # æ”¹è¿›ï¼šä¼˜å…ˆä½¿ç”¨å¤ç”¨é¡µé¢
                    v_page_id = self.page_managers[layer_idx].allocate_reused_page()
                    
                    # è½¬ç½®å­˜å‚¨ï¼š(64, M) -> (M, 64)
                    v_page_data = self.page_managers[layer_idx].get_page(v_page_id)  # (M, 64)
                    v_page_data[:, :] = v_codes[b, h, :, :].transpose(0, 1)  # è½¬ç½®å¹¶å­˜å‚¨
                    
                    # è®°å½•é¡µé¢ID
                    self.value_page_ids[layer_idx][b][h].append(v_page_id)
                    successful_v_allocations += 1
                    
                    logger.debug(f"Layer {layer_idx}: Successfully allocated V page {v_page_id} for batch {b}, head {h}")
                    
                except RuntimeError as e:
                    logger.error(f"Failed to allocate V page for layer {layer_idx}, batch {b}, head {h}: {e}")
                    # è®°å½•å¤±è´¥çš„åˆ†é…ï¼Œä½†ä¸breakï¼Œç»§ç»­å¤„ç†å…¶ä»–batch-headç»„åˆ
                    failed_v_allocations.append((b, h))
        
        # ç»Ÿè®¡åˆ†é…ç»“æœ
        total_allocations = self.bs * self.num_key_value_heads
        logger.info(f"Layer {layer_idx}: V matrix page allocation completed. "
                   f"Success: {successful_v_allocations}/{total_allocations} (failed: {len(failed_v_allocations)})")
        
        # å¦‚æœæœ‰åˆ†é…å¤±è´¥çš„æƒ…å†µï¼Œä½¿ç”¨fallbackç­–ç•¥
        if failed_v_allocations:
            logger.warning(f"Layer {layer_idx}: {len(failed_v_allocations)} V page allocations failed, using fallback")
            
            # VçŸ©é˜µfallback
            fallback_v_codes = []
            for b, h in failed_v_allocations:
                fallback_v_codes.append(v_codes[b:b+1, h:h+1, :, :])
            
            if fallback_v_codes:
                fallback_v_codes = torch.cat(fallback_v_codes, dim=0)
                self.value_cache[layer_idx] = torch.cat([self.value_cache[layer_idx], fallback_v_codes], dim=2)
                logger.debug(f"Layer {layer_idx}: Added {len(fallback_v_codes)} failed V allocations to value_cache")
        
        # ç§»åŠ¨æ®‹å·®ç¼“å­˜ï¼šä¿ç•™åé¢çš„token
        remaining_tokens = self.residualed_tokens[layer_idx] - self.page_size
        
        logger.debug(f"ç§»åŠ¨æ®‹å·®ç¼“å­˜å‰çš„çŠ¶æ€:")
        logger.debug(f"  remaining_tokens: {remaining_tokens}")
        logger.debug(f"  key_residual_cache[{layer_idx}]å½¢çŠ¶: {self.key_residual_cache[layer_idx].shape}")
        logger.debug(f"  value_residual_cache[{layer_idx}]å½¢çŠ¶: {self.value_residual_cache[layer_idx].shape}")
        
        if remaining_tokens > 0:
            # å°†åé¢çš„tokenç§»åˆ°å‰é¢
            # ä½¿ç”¨clone()é¿å…å¼•ç”¨é—®é¢˜
            key_src = self.key_residual_cache[layer_idx][:, :, self.page_size:self.residualed_tokens[layer_idx], :].clone()
            value_src = self.value_residual_cache[layer_idx][:, :, self.page_size:self.residualed_tokens[layer_idx], :].clone()
            
            # æ¸…ç©ºç›®æ ‡åŒºåŸŸ
            self.key_residual_cache[layer_idx][:, :, :remaining_tokens, :].fill_(0)
            self.value_residual_cache[layer_idx][:, :, :remaining_tokens, :].fill_(0)
            
            # å¤åˆ¶æ•°æ®
            self.key_residual_cache[layer_idx][:, :, :remaining_tokens, :] = key_src
            self.value_residual_cache[layer_idx][:, :, :remaining_tokens, :] = value_src
        else:
            # å¦‚æœremaining_tokens <= 0ï¼Œæ¸…ç©ºæ®‹å·®ç¼“å­˜
            self.key_residual_cache[layer_idx].fill_(0)
            self.value_residual_cache[layer_idx].fill_(0)
        
        # æ›´æ–°è®¡æ•°
        self.residualed_tokens[layer_idx] = remaining_tokens
        self.seen_tokens[layer_idx] += self.page_size
        
        logger.debug(f"Layer {layer_idx}: Flush completed. Remaining residual tokens: {remaining_tokens}")
    
    def prefill(self, query_states, key_states, value_states, layer_idx, distort_recent=False):
        """
        é¡µå¼é¢„å¡«å……æ–¹æ³• - ä¼˜åŒ–é¢„å¡«å……é˜¶æ®µçš„é¡µé¢å­˜å‚¨
        
        æ”¹è¿›ï¼šKçŸ©é˜µä½¿ç”¨ä¼ ç»Ÿå­˜å‚¨ï¼ˆä¼˜åŒ–attentionè®¡ç®—ï¼‰ï¼ŒVçŸ©é˜µä½¿ç”¨è½¬ç½®å­˜å‚¨ï¼ˆä¼˜åŒ–å†…å­˜è®¿é—®ï¼‰
        
        Args:
            query_states: Queryå¼ é‡ (bs, nh, prefill_length, d)
            key_states: Keyå¼ é‡ (bs, nh_k, prefill_length, d)
            value_states: Valueå¼ é‡ (bs, nh_k, prefill_length, d)
            layer_idx: å±‚ç´¢å¼•
            distort_recent: æ˜¯å¦åœ¨prefillé˜¶æ®µä½¿ç”¨é‡åŒ–æ•°æ®
            
        Returns:
            attention_output: æ³¨æ„åŠ›è¾“å‡º
        """
        logger.debug(f"PagedPQCache prefill: layer={layer_idx}, tokens={key_states.size(2)}, distort_recent={distort_recent}")
        
        # æ ‡è®°å½“å‰å¤„äºprefillé˜¶æ®µï¼Œé¿å…é¡µé¢è¦†ç›–
        self._is_prefill_phase = True
        
        with Timer("PagedPQCache.prefill"):
            prefill_length = key_states.size(2)
            
            # æ€»æ˜¯è¿›è¡Œé‡åŒ–ç¼–ç å’Œå­˜å‚¨
            with Timer("PagedPQCache.prefill.encode"):
                key_codes = sa_encode_4d_keops(key_states, self.key_cent, target_dtype=self.dtype)
                value_codes = sa_encode_4d_keops(value_states, self.value_cent, target_dtype=self.dtype)
                # å‡å°‘åŒæ­¥è°ƒç”¨ï¼Œåªåœ¨å¿…è¦æ—¶åŒæ­¥
                # torch.cuda.synchronize()
            
            # æ”¹è¿›ï¼šKçŸ©é˜µä½¿ç”¨ä¼ ç»Ÿå­˜å‚¨ï¼ˆrow-wiseï¼‰ï¼Œä¼˜åŒ–attentionè®¡ç®—
            with Timer("PagedPQCache.prefill.store_k_traditional"):
                # KçŸ©é˜µç›´æ¥å­˜å‚¨åˆ°key_cacheï¼Œä¿æŒä¼ ç»Ÿæ ¼å¼
                self.key_cache[layer_idx] = torch.cat([self.key_cache[layer_idx], key_codes], dim=2)
                # å‡å°‘åŒæ­¥è°ƒç”¨
                # torch.cuda.synchronize()
                
                logger.info(f"Layer {layer_idx}: K matrix stored traditionally in key_cache "
                           f"(shape: {self.key_cache[layer_idx].shape})")
            
            # VçŸ©é˜µï¼šæŒ‰é¡µé¢å­˜å‚¨ï¼ˆè½¬ç½®æ ¼å¼ï¼‰ï¼Œä¼˜åŒ–å†…å­˜è®¿é—®
            with Timer("PagedPQCache.prefill.store_v_pages"):
                start_time = torch.cuda.Event(enable_timing=True)
                end_time = torch.cuda.Event(enable_timing=True)
                start_time.record()
                
                batch_size = self.page_size
                num_batches = (prefill_length + batch_size - 1) // batch_size
                total_v_pages_needed = self.bs * self.num_key_value_heads * num_batches
                
                # è¯¦ç»†è®°å½•é¡µé¢éœ€æ±‚è®¡ç®—
                logger.info(f"Layer {layer_idx}: é¡µé¢éœ€æ±‚è®¡ç®—è¯¦æƒ…:")
                logger.info(f"  - prefill_length: {prefill_length}")
                logger.info(f"  - page_size: {batch_size}")
                logger.info(f"  - num_batches: {num_batches}")
                logger.info(f"  - bs: {self.bs}, num_key_value_heads: {self.num_key_value_heads}")
                logger.info(f"  - total_v_pages_needed: {total_v_pages_needed}")
                
                pm = self.page_managers[layer_idx]
                available_pages = len(pm.free_pages)
                if available_pages < total_v_pages_needed:
                    logger.warning(f"Layer {layer_idx}: Insufficient pages available ({available_pages}/{total_v_pages_needed}). Attempting to expand page pool...")
                    try:
                        delta = total_v_pages_needed - available_pages
                        if pm.max_pages is not None and pm.current_active_pages + delta > pm.max_pages:
                            # è®¡ç®—çœŸæ­£éœ€è¦çš„æ€»é¡µé¢æ•°
                            total_needed = pm.current_active_pages + delta
                            logger.warning(f"Layer {layer_idx}: é¡µé¢æ± çŠ¶æ€ - å½“å‰æ¿€æ´»: {pm.current_active_pages}, å¯ç”¨: {available_pages}, éœ€è¦: {total_v_pages_needed}")
                            logger.warning(f"Layer {layer_idx}: éœ€è¦æ‰©å±•é¡µé¢æ± ï¼Œä½†å—max_pagesé™åˆ¶ ({pm.max_pages})")
                            logger.warning(f"Layer {layer_idx}: å»ºè®®å¢åŠ max_pagesåˆ°è‡³å°‘ {total_needed} (å½“å‰: {pm.current_active_pages} + éœ€è¦: {delta})")
                            # ä¸ä¸´æ—¶æå‡max_pagesï¼Œè®©æ‰©å±•å¤±è´¥ï¼Œä½¿ç”¨fallback
                            raise RuntimeError(f"Page pool expansion blocked by max_pages limit: {pm.max_pages}")
                        pm._expand_page_pool(additional_pages=delta, force_expansion=True)
                        available_pages = len(pm.free_pages)
                        if available_pages < total_v_pages_needed:
                            raise RuntimeError(f"Still insufficient pages after expansion: {available_pages}/{total_v_pages_needed}")
                    except Exception as e:
                        logger.error(f"Layer {layer_idx}: Failed to expand page pool: {e}. Switching to traditional storage mode for V matrix.")
                        with Timer("PagedPQCache.prefill.store_v_traditional_fallback"):
                            self.value_cache[layer_idx] = torch.cat([self.value_cache[layer_idx], value_codes], dim=2)
                            logger.info(f"Layer {layer_idx}: V matrix stored traditionally (fallback mode)")
                        logger.info(f"Layer {layer_idx}: Skipping page allocation due to expansion failure")
                        return self._compute_attention_fallback(query_states, key_states, value_states, layer_idx)
                
                logger.info(f"Layer {layer_idx}: V matrix needs {total_v_pages_needed} pages ({self.bs} batch Ã— {self.num_key_value_heads} heads Ã— {num_batches} batches)")
                
                successful_v_pages = 0
                failed_v_pages = 0
                
                # é¢„è½¬ç½®ç¼–ç ï¼Œå‡å°‘å¾ªç¯å†…è½¬ç½®å¼€é”€
                # value_codes: (bs, nh_k, T, M) -> æˆ‘ä»¬æŒ‰å°å—åˆ‡ç‰‡åå†è½¬ç½®
                for batch_idx in range(num_batches):
                    start_idx = batch_idx * batch_size
                    end_idx = min(start_idx + batch_size, prefill_length)
                    current_batch_size = end_idx - start_idx
                    # (bs, nh_k, current_batch_size, M)
                    chunk = value_codes[:, :, start_idx:end_idx, :]
                    # ç›®æ ‡é¡µå½¢çŠ¶ (bs, nh_k, M, page_size)ï¼Œå…ˆåˆ›å»ºä¸´æ—¶buffer
                    # ä»…å½“ä¸è¶³ä¸€é¡µæ—¶ï¼Œæ‰éœ€è¦é›¶å¡«å……å°¾éƒ¨
                    transposed = chunk.permute(0, 1, 3, 2).contiguous()  # (bs, nh_k, M, current_batch_size)
                    if current_batch_size < self.page_size:
                        pad_cols = self.page_size - current_batch_size
                        pad = torch.zeros((self.bs, self.num_key_value_heads, self.M, pad_cols), dtype=transposed.dtype, device=transposed.device)
                        transposed = torch.cat([transposed, pad], dim=3)
                    # ç°åœ¨ transposed å½¢çŠ¶ä¸º (bs, nh_k, M, page_size)
                    
                    # æ‰¹é‡åˆ†é…æœ¬å°æ‰¹éœ€è¦çš„é¡µé¢
                    pages_needed = self.bs * self.num_key_value_heads
                    try:
                        page_ids = pm.allocate_pages(pages_needed)
                    except RuntimeError as e:
                        logger.error(f"Layer {layer_idx}: bulk allocate failed: {e}")
                        # å›é€€ä¸ºå•ä¸ªåˆ†é…
                        page_ids = []
                        for _ in range(pages_needed):
                            try:
                                page_ids.append(pm.allocate_reused_page())
                            except RuntimeError as ee:
                                logger.error(f"Layer {layer_idx}: allocate_reused_page failed: {ee}")
                                page_ids.append(-1)
                    
                    # æ‰¹é‡å†™å…¥é¡µé¢
                    idx = 0
                    for b in range(self.bs):
                        for h in range(self.num_key_value_heads):
                            pid = page_ids[idx] if idx < len(page_ids) else -1
                            idx += 1
                            if pid == -1:
                                # å¤±è´¥fallbackè¯¥(b,h)
                                fallback_value_codes = chunk[b:b+1, h:h+1, :, :]
                                if self.value_cache[layer_idx].size(2) == 0:
                                    self.value_cache[layer_idx] = fallback_value_codes
                                else:
                                    expanded_fallback = fallback_value_codes.expand(self.bs, self.num_key_value_heads, -1, -1)
                                    self.value_cache[layer_idx] = torch.cat([self.value_cache[layer_idx], expanded_fallback], dim=2)
                                failed_v_pages += 1
                                continue
                            page_data = pm.get_page(pid)
                            # ç›´æ¥sliceèµ‹å€¼
                            page_data[:, :] = transposed[b, h]
                            # ç›´æ¥è®¾ç½®é¡µé¢IDï¼Œé¿å…è¦†ç›–æ£€æŸ¥
                            self._direct_set_value_page(layer_idx, b, h, batch_idx, pid)
                            successful_v_pages += 1
                
                end_time.record()
                # åªåœ¨æœ€åè¿›è¡Œä¸€æ¬¡åŒæ­¥ï¼Œå‡å°‘åŒæ­¥å¼€é”€
                torch.cuda.synchronize()
                elapsed_time = start_time.elapsed_time(end_time)
                
                v_success_rate = (successful_v_pages / total_v_pages_needed * 100) if total_v_pages_needed > 0 else 0
                logger.info(f"Layer {layer_idx}: V matrix page allocation completed. Success: {successful_v_pages}/{total_v_pages_needed} ({v_success_rate:.1f}%), Time: {elapsed_time:.2f} ms")
                page_stats = pm.get_stats()
                logger.info(f"Layer {layer_idx}: Page reuse stats - Reuse rate: {page_stats['reuse_rate_percent']:.1f}%, Total allocations: {page_stats['total_allocations']}")
                pages_per_ms = successful_v_pages / elapsed_time if elapsed_time > 0 else 0
                logger.info(f"Layer {layer_idx}: Performance - {pages_per_ms:.2f} pages/ms")

            # å¦‚æœéœ€è¦distort_recentï¼Œåé‡åŒ–ç”¨äºattentionè®¡ç®—
            if distort_recent:
                with Timer("PagedPQCache.prefill.decode"):
                    key_states = sa_decode_4d(key_codes, self.key_cent)
                    value_states = sa_decode_4d(value_codes, self.value_cent)
                    # å‡å°‘åŒæ­¥è°ƒç”¨
                    # torch.cuda.synchronize()
            
            # æ‰§è¡Œæ³¨æ„åŠ›è®¡ç®—
            with Timer("PagedPQCache.prefill.attention"):
                from torch.nn.functional import scaled_dot_product_attention as sdpa
                from transformers.models.llama.modeling_llama import repeat_kv

                num_heads = query_states.size(1)
                num_kv_heads = key_states.size(1)
                nrep = num_heads // num_kv_heads

                key_states = repeat_kv(key_states, nrep)
                value_states = repeat_kv(value_states, nrep)
                
                attention_output = sdpa(query_states, key_states, value_states, is_causal=True)
                
                logger.debug(f"PagedPQCache prefill completed: layer={layer_idx}, "
                           f"K_traditional={self.key_cache[layer_idx].size(2)} tokens, "
                           f"V_pages={sum(len(self.value_page_ids[layer_idx][b][h]) for b in range(self.bs) for h in range(self.num_key_value_heads))}")
                
                # æ¸…é™¤prefillé˜¶æ®µæ ‡è®°
                self._is_prefill_phase = False
                
                return attention_output
    
    def update(self, key_states, value_states, layer_idx, distort_recent=False):
        """
        é‡å†™çˆ¶ç±»çš„updateæ–¹æ³•ï¼Œç¡®ä¿æ­£ç¡®ç®¡ç†é¡µé¢å­˜å‚¨
        
        Args:
            key_states: Keyå¼ é‡ (bs, nh_k, update_length, d)
            value_states: Valueå¼ é‡ (bs, nh_k, update_length, d)
            layer_idx: å±‚ç´¢å¼•
            distort_recent: æ˜¯å¦åœ¨prefillé˜¶æ®µä½¿ç”¨é‡åŒ–æ•°æ®
            
        Returns:
            key_states, value_states: æ›´æ–°åçš„KVçŠ¶æ€
        """
        # ç›´æ¥è°ƒç”¨çˆ¶ç±»çš„updateæ–¹æ³•ï¼Œå› ä¸ºprefillé˜¶æ®µç°åœ¨ç›´æ¥è¿›è¡Œé¡µé¢å­˜å‚¨
        # ä¸éœ€è¦å¤æ‚çš„æ®‹å·®ç¼“å­˜ç®¡ç†
        key_states, value_states = super().update(key_states, value_states, layer_idx, distort_recent)
        
        return key_states, value_states
    
    def decoding_with_pages(self, query_states, key_states, value_states, layer_idx):
        """
        ä½¿ç”¨é¡µé¢å­˜å‚¨çš„è§£ç attention - è°ƒç”¨çœŸæ­£çš„é¡µå¼CUDAå†…æ ¸
        
        Args:
            query_states: Queryå¼ é‡ (bs, nh, 1, d)
            key_states: Keyå¼ é‡ (bs, nh_k, 1, d)  
            value_states: Valueå¼ é‡ (bs, nh_k, 1, d)
            layer_idx: å±‚ç´¢å¼•
            
        Returns:
            attention_output: æ³¨æ„åŠ›è¾“å‡º
        """
        # ç¡®ä¿å½“å‰å¤„äºdecodingé˜¶æ®µï¼Œå…è®¸é¡µé¢è¦†ç›–
        self._is_prefill_phase = False
        
        try:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦flush
            if self.residualed_tokens[layer_idx] >= self.extended_residual_size:
                logger.debug(f"Layer {layer_idx}: Residual cache full, flushing to pages")
                self.flush_to_pages(layer_idx)
            
            # æ·»åŠ æ–°tokenåˆ°æ®‹å·®ç¼“å­˜
            r = self.residualed_tokens[layer_idx]
            n = key_states.size(2)  # æ–°tokenæ•°é‡
            
            # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿æ®‹å·®ç¼“å­˜æœ‰è¶³å¤Ÿç©ºé—´
            if r + n > self.extended_residual_size:
                logger.warning(f"Layer {layer_idx}: Residual cache overflow detected: {r + n} > {self.extended_residual_size}. Force flushing.")
                self.flush_to_pages(layer_idx)
                r = self.residualed_tokens[layer_idx]
            
            # å®‰å…¨æ£€æŸ¥ï¼šé¡µé¢ç®¡ç†å™¨çŠ¶æ€
            page_stats = self.page_managers[layer_idx].get_stats()
            if page_stats['free_pages'] < 2:  # ä¿ç•™è‡³å°‘2ä¸ªç©ºé—²é¡µé¢
                logger.warning(f"Layer {layer_idx}: Low memory warning - only {page_stats['free_pages']} pages remaining")
            
            self.key_residual_cache[layer_idx][:, :, r:r+n, :] = key_states
            self.value_residual_cache[layer_idx][:, :, r:r+n, :] = value_states
            self.residualed_tokens[layer_idx] += n
            self.seen_tokens[layer_idx] += n
            
            logger.debug(f"Layer {layer_idx}: Added {n} tokens, total residual: {self.residualed_tokens[layer_idx]}")
            
            # è°ƒç”¨çœŸæ­£çš„é¡µå¼CUDAå†…æ ¸
            return self._call_paged_kernel(query_states, layer_idx, r + n)
            
        except Exception as e:
            logger.error(f"PagedPQCache decoding failed at layer {layer_idx}: {e}. Falling back to standard decoding.")
            # å¦‚æœé¡µå¼å¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°æ ‡å‡†å¤„ç†
            # ç¡®ä¿çŠ¶æ€ä¸€è‡´æ€§
            try:
                self.seen_tokens[layer_idx] += key_states.size(2)
                return super().decoding(query_states, key_states, value_states, layer_idx)
            except Exception as fallback_e:
                logger.critical(f"Fallback decoding also failed: {fallback_e}")
                raise
    
    def _call_paged_kernel(self, query_states, layer_idx, residual_length):
        """
        è°ƒç”¨é¡µå¼CUDAå†…æ ¸è¿›è¡Œattentionè®¡ç®—
        
        Args:
            query_states: Queryå¼ é‡ (bs, nh, 1, d)
            layer_idx: å±‚ç´¢å¼•
            residual_length: æ®‹å·®ç¼“å­˜é•¿åº¦
            
        Returns:
            attention_output: æ³¨æ„åŠ›è¾“å‡º
        """
        # ç®€åŒ–çš„fallbackå®ç°
        logger.info(f"Layer {layer_idx}: Using fallback to standard decoding (paged kernel not implemented)")
        return self._fallback_to_standard_decoding(query_states, layer_idx, residual_length)
    
    def _fallback_to_standard_decoding(self, query_states, layer_idx, residual_length):
        """å›é€€åˆ°æ ‡å‡†decodingå®ç°"""
        try:
            logger.info(f"Layer {layer_idx}: Using fallback to standard decoding")
            
            # ä½¿ç”¨çœŸå®çš„key_stateså’Œvalue_statesè¿›è¡Œfallback
            real_key_states = self.key_residual_cache[layer_idx][:, :, :residual_length, :]
            real_value_states = self.value_residual_cache[layer_idx][:, :, :residual_length, :]
            
            # è°ƒç”¨çˆ¶ç±»çš„æ ‡å‡†decodingæ–¹æ³•
            return super().decoding(query_states, real_key_states, real_value_states, layer_idx)
            
        except Exception as fallback_e:
            logger.critical(f"Layer {layer_idx}: Fallback decoding failed: {fallback_e}")
            raise
    
    def _direct_set_value_page(self, layer_idx: int, b: int, h: int, batch_idx: int, page_id: int):
        """ç›´æ¥è®¾ç½®Vé¡µé¢IDï¼Œä¸è¿›è¡Œè¦†ç›–æ£€æŸ¥ï¼ˆç”¨äºprefillé˜¶æ®µçš„æ‰¹é‡åˆ†é…ï¼‰ã€‚"""
        # ç¡®ä¿åˆ—è¡¨é•¿åº¦
        lst = self.value_page_ids[layer_idx][b][h]
        if len(lst) <= batch_idx:
            # ä½¿ç”¨å ä½ç¬¦-1æ‰©å±•
            lst.extend([-1] * (batch_idx + 1 - len(lst)))
        
        # ç›´æ¥è®¾ç½®é¡µé¢IDï¼Œä¸è¿›è¡Œä»»ä½•æ£€æŸ¥
        lst[batch_idx] = int(page_id)
        logger.debug(f"ç›´æ¥è®¾ç½®ï¼šlayer={layer_idx}, batch={b}, head={h}, batch_idx={batch_idx} -> é¡µé¢ {page_id}")
    
    def _compute_attention_fallback(self, query_states, key_states, value_states, layer_idx):
        """
        é¡µé¢åˆ†é…å¤±è´¥æ—¶çš„fallback attentionè®¡ç®—
        
        Args:
            query_states: Queryå¼ é‡
            key_states: Keyå¼ é‡
            value_states: Valueå¼ é‡
            layer_idx: å±‚ç´¢å¼•
            
        Returns:
            attention_output: æ³¨æ„åŠ›è¾“å‡º
        """
        logger.info(f"Layer {layer_idx}: Using fallback attention computation")
        
        # å¦‚æœéœ€è¦distort_recentï¼Œåé‡åŒ–ç”¨äºattentionè®¡ç®—
        if hasattr(self, 'distort_recent') and self.distort_recent:
            with Timer("PagedPQCache.prefill.decode_fallback"):
                key_states = sa_decode_4d(self.key_cache[layer_idx], self.key_cent)
                value_states = sa_decode_4d(self.value_cache[layer_idx], self.value_cent)
                torch.cuda.synchronize()
        
        # æ‰§è¡Œæ³¨æ„åŠ›è®¡ç®—
        with Timer("PagedPQCache.prefill.attention_fallback"):
            from torch.nn.functional import scaled_dot_product_attention as sdpa
            from transformers.models.llama.modeling_llama import repeat_kv

            num_heads = query_states.size(1)
            num_kv_heads = key_states.size(1)
            nrep = num_heads // num_kv_heads

            key_states = repeat_kv(key_states, nrep)
            value_states = repeat_kv(value_states, nrep)
            
            attention_output = sdpa(query_states, key_states, value_states, is_causal=True)
            
            logger.debug(f"PagedPQCache fallback attention completed: layer={layer_idx}")
            
            return attention_output